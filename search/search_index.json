{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Multisensory Intelligence Computing Resources Documentation!","text":"<p>First of all, welcome to the Multisensory Intelligence (MI) group! We are excited to have you here and look forward to collaborating with you on various projects.</p> <p>This documentation is designed to provide you with all the necessary information and resources to get started with our projects.</p>"},{"location":"#mib-server-gpu-utilization-dashboard","title":"MIB Server GPU Utilization Dashboard","text":""},{"location":"#available-resources","title":"Available Resources","text":"<p>As of now, we have two main GPU servers available for use:</p> <ol> <li> <p>Engaging: This is a server node hosted on the MIT Engaging cluster. It has 8 NVIDIA H200 GPUs, each with 144GB of memory. </p> </li> <li> <p>MIB (Multisensory Intelligence Blackwell Server): This is a new server node hosted on the Media Lab cluster. It has 8 NVIDIA RTX 6000 Blackwell MaxQ GPUs, each with 96GB of memory.</p> </li> </ol> <p>In addition, MIT also offers complimentary GPU access, where you can directly request via slurm. </p>"},{"location":"#choosing-the-right-server","title":"Choosing the Right Server","text":"<p>Generally, we recommend choosing the server that is less busy at the time you need it. However, you may want to consider the following factors:</p> <ol> <li>Access: Engaging is configured with Slurm, while MIB allows direct SSH access. If your workflow uses VSCode or other IDEs that require direct access, MIB might be the better choice.</li> <li>GPU Memory: If your tasks require more GPU memory (&gt;96GB), then Engaging is the better option.</li> <li>Framework Compatibility: MIB has the latest Blackwell GPUs, which requires a minimal CUDA version of 12.8. If your code relies on older Pytorch, Engaging might be more compatible.</li> </ol>"},{"location":"#getting-started","title":"Getting Started","text":"<p>After you choose a server, please refer to the following documentation for instructions on how to set up your environment and start using the resources:</p> <ul> <li>Getting Started with Engaging</li> <li>Getting Started with MIB</li> </ul>"},{"location":"engaging/getting_started/","title":"MIT Engaging Cluster Documentation","text":""},{"location":"engaging/getting_started/#introduction","title":"Introduction","text":"<p>The MIT Engaging Cluster is a high-performance computing (HPC) system that provides computational resources for research. This guide will help you get started with accessing and using our lab's resource on the Engaging cluster.</p> <p>This documentation mainly focuses on commandline access to the server. If you prefer to use Jupyter notebooks, please refer to the Jupyter Access Guide.</p>"},{"location":"engaging/getting_started/#getting-started","title":"Getting Started","text":""},{"location":"engaging/getting_started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li> <p>An MIT Kerberos account (your MIT username and password)</p> </li> <li> <p>A terminal application (Terminal on macOS/Linux, or PuTTY/Windows Terminal on Windows)</p> </li> <li> <p>Basic familiarity with Linux command line</p> </li> </ul>"},{"location":"engaging/getting_started/#creating-an-engaging-account","title":"Creating an Engaging Account","text":"<p>You can skip this section if you have used Engaging before. Otherwise, an account can be automatically created for you when you first log in with your MIT credentials.</p> <ol> <li> <p>Open your browser and go to https://engaging-ood.mit.edu/</p> </li> <li> <p>Login with MIT credentials</p> </li> </ol> Troubleshooting login issues <p>If you encounter a traffic error or cannot login:    1. Clear your browser's cache and cookies    2. Try using a different browser or incognito/private mode    3. Ensure you're connected to the MIT network or VPN if off-campus</p>"},{"location":"engaging/getting_started/#requesting-access-to-our-groups-server","title":"Requesting Access to Our Group's Server","text":"<p>Our server's access is currently managed by David. Please follow the following steps to request access:</p> <ol> <li>Get approval from Paul. </li> <li>Email or Slack David at dvdai@mit.edu.</li> <li>Once it's set up, you should be able to request the node in around 30 minutes.</li> </ol>"},{"location":"engaging/getting_started/#ssh-access","title":"SSH Access","text":"<p>SSH (Secure Shell) provides command-line access to the cluster, which is suitable for most tasks.</p>"},{"location":"engaging/getting_started/#basic-ssh-connection","title":"Basic SSH Connection","text":"<p>To connect via SSH, open your terminal and use:</p> <pre><code>ssh &lt;mit_username&gt;@orcd-login001.mit.edu\n</code></pre> <p>For example, if your MIT username is <code>dvdai</code>, you would run: <pre><code>ssh dvdai@orcd-login001.mit.edu\n</code></pre></p> <p>You'll be prompted for your MIT password. After entering it, you'll be connected to the login node.</p> <p>Note</p> <p>The login node is for light tasks only (editing files, submitting jobs). Do NOT run computationally intensive tasks here.</p>"},{"location":"engaging/getting_started/#password-free-ssh-setup","title":"Password-Free SSH Setup","text":"<p>Typing your password repeatedly can be tedious. Set up SSH keys for password-free access:</p> <pre><code># On your local machine, generate an SSH key if you don't have one\nssh-keygen -t rsa -b 4096\n\n# Copy your key to the cluster\nssh-copy-id &lt;mit_username&gt;@orcd-login001.mit.edu\n</code></pre> <p>Tip</p> <p>For detailed SSH key setup, see SSH Copy ID Documentation.</p>"},{"location":"engaging/getting_started/#installing-minicondaanaconda","title":"Installing Miniconda/Anaconda","text":"<p>Most users prefer managing their own Python environments. Here's how to setup your Python environment using Miniconda:</p> <pre><code># Create a directory for Miniconda\nmkdir -p ~/miniconda3\n\n# Download the installer\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n\n# Install Miniconda (the -b flag runs in batch mode, -u updates existing installation, -p specifies path)\nbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\n\n# Remove the installer to save space\nrm ~/miniconda3/miniconda.sh\n\n# Activate Miniconda for current session\nsource ~/miniconda3/bin/activate\n\n# Initialize conda for all shells (bash, zsh, etc.)\nconda init --all\n</code></pre> <p>Success</p> <p>After running these commands, close and reopen your terminal. You should see <code>(base)</code> before your prompt, indicating conda is active.</p>"},{"location":"engaging/getting_started/#creating-and-managing-conda-environments","title":"Creating and Managing Conda Environments","text":"<p>Environments allow you to have different versions of packages for different projects without conflicts.</p> <pre><code># Create a new environment with specific Python version\nconda create --name myproject python=3.12\n\n# Activate the environment\nconda activate myproject\n\n# You can install torch via\npip install torch torchvision\n</code></pre>"},{"location":"engaging/getting_started/#using-persistent-sessions-with-tmux","title":"Using Persistent Sessions with tmux","text":"<p>When running long jobs via SSH, your session might disconnect. Use tmux to keep sessions running:</p> <pre><code># Start a new tmux session\ntmux\n\n# Or start with a named session\ntmux new -s mysession\n\n# Detach from session (keeps it running)\n# Press: Ctrl+b, then d\n\n# List active sessions\ntmux ls\n\n# Reattach to a session\ntmux attach -t mysession\n\n# Kill a session\ntmux kill-session -t mysession\n</code></pre>"},{"location":"engaging/getting_started/#requesting-computational-resources","title":"Requesting Computational Resources","text":"<p>The cluster uses SLURM to manage computational resources. You request resources, and SLURM allocates them when available.</p>"},{"location":"engaging/getting_started/#interactive-gpu-sessions","title":"Interactive GPU Sessions","text":"<p>For development and testing, request an interactive session with GPU:</p> <pre><code>srun --gres=gpu:1 --time=03:05:00 -p pi_ppliang --nodelist=node2500 -c 15 --mem=65G --pty bash\n</code></pre> <p>Breaking down the parameters:</p> <ul> <li><code>--gres=gpu:1</code>: Number of GPUs (max 8 for our group)</li> <li><code>--time=03:05:00</code>: Time limit in HH:MM:SS format (max 168:00:00 = 7 days)</li> <li><code>-p pi_ppliang</code>: Partition (queue) name for our research group. Our groups is <code>pi_ppliang</code>. If you want to use MIT's free GPUs, use <code>mit_normal_gpu</code> instead.</li> <li><code>--nodelist=node2500</code>: Specific node to use (optional, remove for any available node)</li> <li><code>-c 15</code>: Number of CPU cores (generally 15 cores per GPU is reasonable)</li> <li><code>--mem=65G</code>: Memory allocation (max ~250GB per GPU, but be considerate)</li> <li><code>--pty bash</code>: Launch an interactive bash shell</li> </ul>"},{"location":"engaging/getting_started/#using-mits-free-gpu-resources","title":"Using MIT's Free GPU Resources","text":"<p>MIT provides free GPUs with shorter time limits for general use:</p> <pre><code>srun --gres=gpu:1 --time=06:00:00 -p mit_normal_gpu -c 15 --mem=65G --pty bash\n</code></pre> <p>The exact GPU and compute resources limit for the free partition varies based on the current load. </p>"},{"location":"engaging/getting_started/#checking-and-managing-jobs","title":"Checking and Managing Jobs","text":"<p>When requesting resources, your job may not start immediately if resources are unavailable. You can check the current status of your jobs via:</p> <pre><code>squeue --me\n</code></pre> <p>If it says <code>(Resources)</code>, it means the requested resources aren't currently available. You can check who is using the resources on our node:</p> <pre><code>squeue -w node2500 -o \"%.18i %.8u %.8T %.10M %.6D %C %m %b\"\n</code></pre> <p>In general, we ask that you only request what you need, and release resources when you're done. If you see someone is using more than 2 GPUs for a long time, feel free to reach out to them to see if they can release some.</p> <p>Creating a Convenience Function</p> <p>You may add this function to your <code>~/.bashrc</code> file to simplify GPU requests:</p> <pre><code># Open your bashrc file\nnano ~/.bashrc\n\n# Add this function at the end\ngetgpu() {\n    local gpu_count=\"${1:-1}\"\n    local mem=\"${2:-32G}\"\n    local time=\"${3:-03:05:00}\"\n    echo \"Requesting $gpu_count GPU(s) with $mem memory for $time...\"\n    srun --mem=\"$mem\" --gres=\"gpu:$gpu_count\" --time=\"$time\" -p pi_ppliang --nodelist=node2500 --pty bash\n}\n\n# Save and exit (Ctrl+X, then Y, then Enter)\n\n# Reload your bashrc\nsource ~/.bashrc\n</code></pre> <p>Usage examples: <pre><code># Request 1 GPU with defaults (32G memory, 3:05:00 time)\ngetgpu\n\n# Request 2 GPUs with 64G memory\ngetgpu 2 64G\n\n# Request 1 GPU with 128G memory for 12 hours\ngetgpu 1 128G 12:00:00\n</code></pre></p>"},{"location":"engaging/getting_started/#verifying-gpu-access","title":"Verifying GPU Access","text":"<p>Once you have a GPU allocated, verify it's working:</p> <pre><code># Check GPU status\nnvidia-smi\n</code></pre> <p>You should see something like:</p> <p></p> <p>This shows GPU utilization, memory usage, and running processes.</p>"},{"location":"engaging/getting_started/#installing-and-testing-pytorch","title":"Installing and Testing PyTorch","text":"<p>You can set up PyTorch in your conda environment:</p> <pre><code># Make sure you're in your conda environment\nconda activate myproject\n\n# Install PyTorch with CUDA support\npip3 install torch torchvision\n\n# Test the installation\npython3 -c \"import torch; print(f'CUDA available: {torch.cuda.is_available()}')\"\npython3 -c \"import torch; print(f'Number of GPUs: {torch.cuda.device_count()}')\"\npython3 -c \"import torch; print(f'GPU Name: {torch.cuda.get_device_name(0)}')\"\n</code></pre> <p>Success</p> <p>If properly configured, you should see:</p> <ul> <li> <p><code>CUDA available: True</code></p> </li> <li> <p><code>Number of GPUs: 1</code> (or more if you requested multiple)</p> </li> <li> <p><code>GPU Name: [Your GPU model]</code></p> </li> </ul>"},{"location":"engaging/getting_started/#storage-and-transfer-files","title":"Storage and Transfer files","text":"<p>The cluster provides different storage areas for different purposes:</p> Storage Type Path Quota Backed up Purpose/Notes Home Directory Flash <code>/home/&lt;username&gt;</code> 200 GB Backed up with snapshots Use for important files and software Pool Hard Disk <code>/home/&lt;username&gt;/orcd/pool</code> 1 TB Disaster recovery backup Storing larger datasets Scratch Flash <code>/home/&lt;username&gt;/orcd/scratch</code> 1 TB Not backed up Scratch space for I/O heavy jobs <p>On our node, we also have a total of 28TB NVMe SSD mounted at <code>/scratch</code>, which is not backed up. You can use this for high-speed temporary storage. This folder is not accessible from the login node.</p> <p>Checkout the File Transfer Guide for instructions on transferring files to/from the cluster.</p>"},{"location":"engaging/getting_started/#monitoring-and-management-commands","title":"Monitoring and Management Commands","text":"<p>Useful commands for monitoring cluster usage:</p> <pre><code># Check all your jobs\nsqueue --me\n\n# Check specific node utilization\nsqueue -w node2500 -o \"%.18i %.8u %.8T %.10M %.6D %C %m %b\"\n\n# Check GPU usage on a node\nsqueue -h -w node2500 -t R -o \"%i %u %t %M %C %b\" | grep gpu\n\n# Cancel a job\nscancel &lt;job_id&gt;\n\n# Cancel all your jobs\nscancel -u $USER\n\n# Check your storage quotas\nquota -s\n\n# Find large files in your directories\nfind ~ -type f -size +1G -exec ls -lh {} \\;\n</code></pre>"},{"location":"engaging/getting_started/#resources","title":"Resources","text":"<ol> <li>Official Documentation: ORCD Docs</li> </ol> <p>Success</p> <p>You're now ready to use the MIT Engaging Cluster! Start with small jobs, test your workflows, and scale up as needed. Happy computing!</p>"},{"location":"engaging/jupyter_access/","title":"Jupyter Access","text":""},{"location":"engaging/jupyter_access/#running-jupyter-notebooks","title":"Running Jupyter Notebooks","text":"<p>Jupyter notebooks are great for interactive development. Before following these steps, ensure you have a working Miniconda/Python environment following the Getting Started Guide.</p> <p>First, install JupyterLab in your environment:</p> <pre><code># Activate your environment\nconda activate myproject\n\n# Install JupyterLab and useful extensions\npip install jupyterlab ipywidgets matplotlib\n\n# Install kernel for this environment\npython -m ipykernel install --user --name myproject --display-name \"Python (myproject)\"\n</code></pre>"},{"location":"engaging/jupyter_access/#step-1-request-a-gpu-node-with-resources","title":"Step 1: Request a GPU node with resources","text":"<pre><code>srun --gres=gpu:1 --time=12:00:00 -p pi_ppliang --nodelist=node2500 \\\n     -c4 --mem=32G --pty bash\n</code></pre> <p>Adjust the resources based on your needs. Jupyter itself doesn't need much, but your computations might.</p>"},{"location":"engaging/jupyter_access/#step-2-activate-your-environment","title":"Step 2: Activate your environment","text":"<pre><code>conda activate myproject\n</code></pre>"},{"location":"engaging/jupyter_access/#step-3-start-jupyterlab-on-the-compute-node","title":"Step 3: Start JupyterLab on the compute node","text":"<pre><code># Choose a port number between 1024-65535 (e.g., 8888, 9999, 1717)\njupyter-lab --ip=0.0.0.0 --port=1717 --no-browser\n</code></pre> <p>The output will show something like: <pre><code>[I 2024-01-15 10:30:00.123 ServerApp] Jupyter Server is running at:\n[I 2024-01-15 10:30:00.123 ServerApp] http://node2500:1717/lab?token=abc123def456...\n[I 2024-01-15 10:30:00.123 ServerApp] http://127.0.0.1:1717/lab?token=abc123def456...\n</code></pre></p> <p>Keep this terminal open! Copy the token from the URL - you'll need it.</p>"},{"location":"engaging/jupyter_access/#step-4-create-ssh-tunnel-on-your-local-machine","title":"Step 4: Create SSH tunnel (on your local machine)","text":"<p>Open a new terminal on your local computer and run:</p> <pre><code>ssh -N -L 1717:node2500:1717 &lt;mit_username&gt;@orcd-login001.mit.edu\n</code></pre> <p>This creates a tunnel: - <code>-N</code>: No command execution, just forwarding - <code>-L 1717:node2500:1717</code>: Forward local port 1717 to node2500 port 1717</p> <p>Note</p> <p>This terminal will appear to hang - that's normal! It's maintaining the tunnel.</p>"},{"location":"engaging/jupyter_access/#step-5-access-jupyter-in-your-browser","title":"Step 5: Access Jupyter in your browser","text":"<p>Open your web browser and navigate to: <pre><code>http://127.0.0.1:1717/lab?token=abc123def456...\n</code></pre></p> <p>Use the complete URL with token from Step 3.</p>"},{"location":"engaging/jupyter_access/#step-6-clean-up-when-done","title":"Step 6: Clean up when done","text":"<p>Always clean up to free resources:</p> <ol> <li> <p>Save your work in Jupyter</p> </li> <li> <p>In Jupyter: File \u2192 Shut Down</p> </li> <li> <p>On compute node terminal: Press <code>Ctrl+C</code> to stop JupyterLab</p> </li> <li> <p>On local terminal: Press <code>Ctrl+C</code> to stop the SSH tunnel</p> </li> <li> <p>Type <code>exit</code> on compute node to release the resources</p> </li> </ol>"},{"location":"engaging/transfer_files/","title":"Transfer Files","text":"<p>The cluster provides different storage areas for different purposes:</p> Storage Type Path Quota Backed up Purpose/Notes Home Directory Flash <code>/home/&lt;username&gt;</code> 200 GB Backed up with snapshots Use for important files and software Pool Hard Disk <code>/home/&lt;username&gt;/orcd/pool</code> 1 TB Disaster recovery backup Storing larger datasets Scratch Flash <code>/home/&lt;username&gt;/orcd/scratch</code> 1 TB Not backed up Scratch space for I/O heavy jobs <p>On our node, we also have a total of 28TB NVMe SSD mounted at <code>/scratch</code>, which is not backed up. You can use this for high-speed temporary storage. This folder is not accessible from the login node. </p> <p>If you want to transfer files to/from this folder, you will likely need to first transfer to/from your personal storage (pool at <code>/home/&lt;username&gt;/orcd/pool</code>, or scratch at <code>/home/&lt;username&gt;/orcd/scratch</code>), then move files while on the compute node.</p>"},{"location":"engaging/transfer_files/#uploading-files-to-the-cluster","title":"Uploading Files to the Cluster","text":"<p>The easiest way to transfer files is using <code>rsync</code> over SSH. From your local machine, run: <pre><code># Basic syntax\nrsync -avz &lt;local_path&gt; &lt;mit_username&gt;@orcd-login001.mit.edu:&lt;remote_path&gt;\n\n# Upload a single file\nrsync -avz ~/Documents/data.csv dvdai@orcd-login001.mit.edu:~/\n\n# Upload an entire directory\nrsync -avz ~/Documents/project/ dvdai@orcd-login001.mit.edu:~/project/\n\n# Upload with progress bar\nrsync -avz --progress ~/largefile.zip dvdai@orcd-login001.mit.edu:~/orcd/scratch\n</code></pre></p> <p>Useful <code>rsync</code> flags:</p> <ul> <li> <p><code>-a</code>: Archive mode (preserves permissions, timestamps)</p> </li> <li> <p><code>-v</code>: Verbose (shows files being transferred)</p> </li> <li> <p><code>-z</code>: Compression (faster for text files)</p> </li> <li> <p><code>--progress</code>: Shows transfer progress</p> </li> </ul>"},{"location":"engaging/transfer_files/#downloading-files-from-the-cluster","title":"Downloading Files from the Cluster","text":"<p>From your local machine, use <code>rsync</code> to download files:</p> <pre><code># Download a file to current local directory\nrsync -avz dvdai@orcd-login001.mit.edu:~/results.csv ./\n\n# Download a directory\nrsync -avz dvdai@orcd-login001.mit.edu:~/project/ ~/Downloads/project/\n</code></pre>"},{"location":"engaging/transfer_files/#downloading-from-the-internet","title":"Downloading from the Internet","text":"<p>On the cluster, you can also download files directly from the internet using <code>wget</code> or <code>curl</code>: <pre><code># Direct download with wget\nwget https://example.com/dataset.zip\n\n# Download with custom filename\nwget -O mydata.zip https://example.com/dataset.zip\n\n# Download to specific directory\ncd ~/orcd/scratch\nwget https://example.com/largefile.tar.gz\n</code></pre></p> <p>For Google Drive files, you can use <code>gdown</code>: <pre><code>pip install gdown\ngdown https://drive.google.com/uc?id=FILE_ID\n</code></pre></p> <p>For Kaggle datasets, use the Kaggle CLI: <pre><code>pip install kaggle\nkaggle datasets download -d dataset-name\n</code></pre></p> <p>Back to the Getting Started Guide.</p>"},{"location":"mib/getting_started/","title":"MIB Server Documentation","text":""},{"location":"mib/getting_started/#introduction","title":"Introduction","text":"<p>The MIB Server is a shared computational resource with 8 NVIDIA RTX PRO 6000 GPUs (96GB memory each) available for our research group. This guide will help you get started with accessing and using the MIB server effectively.</p>"},{"location":"mib/getting_started/#mib-server-gpu-utilization-dashboard","title":"MIB Server GPU Utilization Dashboard","text":""},{"location":"mib/getting_started/#getting-started","title":"Getting Started","text":""},{"location":"mib/getting_started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li> <p>Approval to use the server (see below)</p> </li> <li> <p>A terminal application (Terminal on macOS/Linux, or PuTTY/Windows Terminal on Windows)</p> </li> <li> <p>Basic familiarity with Linux command line</p> </li> </ul>"},{"location":"mib/getting_started/#requesting-access","title":"Requesting Access","text":"<p>To get access to the MIB server:</p> <ol> <li>Get approval from Paul if you are an intern or collaborator. If you are an official member of the lab, you don't need additional approval.</li> <li>Contact David at dvdai@mit.edu via email or Slack to request account creation.</li> <li>David will create your account with:</li> <li>Username: <code>&lt;your_username&gt;</code> (typically your MIT username)</li> <li>Default password: <code>&lt;username&gt;@mitmi</code></li> </ol> <p>Warning</p> <p>You will be required to change your password on first login. Choose a strong, secure password.</p>"},{"location":"mib/getting_started/#ssh-access","title":"SSH Access","text":""},{"location":"mib/getting_started/#basic-ssh-connection","title":"Basic SSH Connection","text":"<p>To connect to the MIB server, open your terminal and use:</p> <pre><code>ssh &lt;username&gt;@mib.media.mit.edu\n</code></pre> <p>For example, if your username is <code>dvdai</code>: <pre><code>ssh dvdai@mib.media.mit.edu\n</code></pre></p> <p>Note</p> <p>Remember your new password! There's no automatic password recovery system, so you'll need to contact David if you forget it.</p>"},{"location":"mib/getting_started/#password-free-ssh-setup","title":"Password-Free SSH Setup","text":"<p>After your first login, you can set up SSH keys to avoid typing your password every time:</p> <pre><code># On your local machine, generate an SSH key if you don't have one\nssh-keygen -t rsa -b 4096\n\n# Copy your key to the MIB server\nssh-copy-id &lt;username&gt;@mib.media.mit.edu\n</code></pre> <p>This will ask for your password one last time. After this, you can connect without entering a password.</p>"},{"location":"mib/getting_started/#environment-setup","title":"Environment Setup","text":""},{"location":"mib/getting_started/#installing-miniconda","title":"Installing Miniconda","text":"<p>You probably use Python if you are a member of our group. We recommend using Miniconda to manage your Python environments and packages:</p> <pre><code># Create a directory for Miniconda\nmkdir -p ~/miniconda3\n\n# Download the installer\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n\n# Install Miniconda\nbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\n\n# Remove the installer to save space\nrm ~/miniconda3/miniconda.sh\n\n# Activate Miniconda for current session\nsource ~/miniconda3/bin/activate\n\n# Initialize conda for all shells\nconda init --all\n</code></pre> <p>Success</p> <p>After running these commands, close and reconnect to your SSH session. You should see <code>(base)</code> before your prompt, indicating conda is active.</p>"},{"location":"mib/getting_started/#creating-a-conda-environment","title":"Creating a Conda Environment","text":"<p>Create isolated environments for different projects:</p> <pre><code># Create a new environment with specific Python version\nconda create --name myproject python=3.12\n\n# Activate the environment\nconda activate myproject\n\n# Install PyTorch with CUDA support\npip install torch torchvision\n\n# Verify the installation\npython -c \"import torch; print(f'CUDA available: {torch.cuda.is_available()}')\"\npython -c \"import torch; print(f'Number of GPUs: {torch.cuda.device_count()}')\"\n</code></pre>"},{"location":"mib/getting_started/#using-persistent-sessions-with-tmux","title":"Using Persistent Sessions with tmux","text":"<p>Since the MIB server doesn't have a job scheduler, you'll run processes directly. Use tmux to keep them running even if your SSH connection drops:</p> <pre><code># Start a new tmux session\ntmux\n\n# Or start with a named session\ntmux new -s training\n\n# Detach from session (keeps it running)\n# Press: Ctrl+b, then d\n\n# List active sessions\ntmux ls\n\n# Reattach to a session\ntmux attach -t training\n\n# Kill a session when done\ntmux kill-session -t training\n</code></pre>"},{"location":"mib/getting_started/#gpu-usage-and-management","title":"GPU Usage and Management","text":"<p>The MIB server has 8 NVIDIA RTX PRO 6000 GPUs, each with 96GB of memory. Unlike cluster systems with SLURM, there's no automatic resource allocation - please be considerate of others.</p> <p>Check current GPU usage with: <pre><code>nvidia-smi\n</code></pre></p> <p>You'll see output similar to this:</p> <pre><code>+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |\n+-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|=========================================+========================+======================|\n|   0  NVIDIA RTX PRO 6000 Blac...    Off |   00000000:01:00.0 Off |                  Off |\n| 30%   26C    P8              3W /  300W |   45678MiB /  97887MiB |     85%      Default |\n+-----------------------------------------+------------------------+----------------------+\n|   1  NVIDIA RTX PRO 6000 Blac...    Off |   00000000:21:00.0 Off |                  Off |\n| 30%   26C    P8              3W /  300W |   67890MiB /  97887MiB |     90%      Default |\n+-----------------------------------------+------------------------+----------------------+\n|   2  NVIDIA RTX PRO 6000 Blac...    Off |   00000000:41:00.0 Off |                  Off |\n| 30%   26C    P8             11W /  300W |   23456MiB /  97887MiB |     45%      Default |\n+-----------------------------------------+------------------------+----------------------+\n|   3  NVIDIA RTX PRO 6000 Blac...    Off |   00000000:61:00.0 Off |                  Off |\n| 30%   26C    P8              2W /  300W |   78901MiB /  97887MiB |     95%      Default |\n+-----------------------------------------+------------------------+----------------------+\n|   4  NVIDIA RTX PRO 6000 Blac...    Off |   00000000:81:00.0 Off |                  Off |\n| 30%   27C    P8              6W /  300W |   34567MiB /  97887MiB |     60%      Default |\n+-----------------------------------------+------------------------+----------------------+\n|   5  NVIDIA RTX PRO 6000 Blac...    Off |   00000000:A1:00.0 Off |                  Off |\n| 30%   26C    P8              3W /  300W |   12345MiB /  97887MiB |     30%      Default |\n+-----------------------------------------+------------------------+----------------------+\n|   6  NVIDIA RTX PRO 6000 Blac...    Off |   00000000:C1:00.0 Off |                  Off |\n| 30%   25C    P8             11W /  300W |       0MiB /  97887MiB |      0%      Default |\n+-----------------------------------------+------------------------+----------------------+\n|   7  NVIDIA RTX PRO 6000 Blac...    Off |   00000000:E1:00.0 Off |                  Off |\n| 30%   26C    P8              4W /  300W |       0MiB /  97887MiB |      0%      Default |\n+-----------------------------------------+------------------------+----------------------+\n</code></pre> <p>In this example: - GPUs 0-5 are in use (showing memory allocation) - GPUs 6-7 are available (0MiB memory usage)</p> <p>Now you can choose any of the free GPUs (6 or 7 in this case) for your tasks. In general, follow these guidelines:</p> <ol> <li> <p>Always check availability first with <code>nvidia-smi</code></p> </li> <li> <p>Prioritize higher-numbered GPUs i.e. (6, 7), as others may forget to select specific GPUs and occupy lower-numbered ones (0-3). In addition, GPUs 0-3 are in the same block, while 4-7 are in another block. Whenever possible, try to use GPUs from the same block for multi-GPU training.</p> </li> <li> <p>Check for idle processes - if you see memory allocated but 0% utilization for extended periods, consider reaching out to the user or David. </p> </li> </ol> GPU Interconnect Topology <p>The RTX PRO 6000 GPUs are connected in a hybrid topology:</p> GPU0 GPU1 GPU2 GPU3 GPU4 GPU5 GPU6 GPU7 CPU Affinity GPU0 X NODE NODE NODE SYS SYS SYS SYS 0-31,64-95 GPU1 NODE X NODE NODE SYS SYS SYS SYS 0-31,64-95 GPU2 NODE NODE X NODE SYS SYS SYS SYS 0-31,64-95 GPU3 NODE NODE NODE X SYS SYS SYS SYS 0-31,64-95 GPU4 SYS SYS SYS SYS X NODE NODE NODE 32-63,96-127 GPU5 SYS SYS SYS SYS NODE X NODE NODE 32-63,96-127 GPU6 SYS SYS SYS SYS NODE NODE X NODE 32-63,96-127 GPU7 SYS SYS SYS SYS NODE NODE NODE X 32-63,96-127 <p>GPUs with <code>node</code> connection have faster link speed than <code>sys</code> connection. For multi-GPU training, try to use GPUs within the same block (0-3 or 4-7) for better performance.</p>"},{"location":"mib/getting_started/#controlling-gpu-access-with-cuda_visible_devices","title":"Controlling GPU Access with CUDA_VISIBLE_DEVICES","text":"<p>Since there's no job scheduler, you control which GPUs your code uses with the <code>CUDA_VISIBLE_DEVICES</code> environment variable:</p> <pre><code># Use only GPU 6\nCUDA_VISIBLE_DEVICES=6 python train.py\n\n# Use GPUs 6 and 7\nCUDA_VISIBLE_DEVICES=6,7 python train.py\n</code></pre> <p>When you set <code>CUDA_VISIBLE_DEVICES=6,7</code>, your code will see these as GPU 0 and 1. PyTorch/TensorFlow will automatically map them correctly. You do NOT need to add something like <code>device = torch.device(\"cuda:6\")</code> in your code.</p> <p>For example, in PyTorch:</p> <pre><code># In your Python script, after setting CUDA_VISIBLE_DEVICES=6,7\nimport torch\n\n# This will use GPU 6 (appears as device 0 to PyTorch)\ndevice = torch.device(\"cuda:0\")\n\n# This will use GPU 7 (appears as device 1 to PyTorch)\ndevice = torch.device(\"cuda:1\")\n\n# Check available GPUs from Python\nprint(f\"Number of GPUs visible: {torch.cuda.device_count()}\")  # Will show 2\n</code></pre>"},{"location":"mib/getting_started/#monitoring-your-gpu-usage","title":"Monitoring Your GPU Usage","text":"<p>While your code is running, monitor GPU usage in another terminal:</p> <pre><code># Watch GPU usage in real-time (updates every 2 seconds)\nwatch -n 2 nvidia-smi\n\n# Or use nvidia-smi with loop\nnvidia-smi -l 2\n\n# Check only specific GPUs\nnvidia-smi -i 6,7\n</code></pre> <p>To see who is using which GPUs: <pre><code># Show all processes using GPUs\nnvidia-smi | grep python\n\n# Or use the query format for cleaner output\nnvidia-smi --query-compute-apps=pid,process_name,used_gpu_memory --format=csv\n</code></pre></p>"},{"location":"mib/getting_started/#storage-management","title":"Storage Management","text":""},{"location":"mib/getting_started/#storage-overview","title":"Storage Overview","text":"<p>The MIB server has the following storage that are shared among users:</p> Storage Location Path Capacity Purpose Home Directory <code>/home/&lt;username&gt;</code> 50 GB per user Scripts, code, small files Scratch Storage <code>/scratch</code> 28 TB shared for all Datasets, checkpoints, outputs <p>The <code>/scratch</code> directory is also soft linked to your home directory for convenience. You can access it via <code>~/scratch</code>.</p> <p>Note</p> <p>We only have a total of 880 GB in <code>/home</code> for all users combined. Please use the <code>scratch</code> folder whenever possible. You can create your own subdirectories in <code>/scratch</code> via <code>mkdir -p ~/scratch/&lt;your_folder&gt;</code>.</p>"},{"location":"mib/getting_started/#useful-commands","title":"Useful Commands","text":"<p>Monitor and manage your storage usage:</p> <pre><code># Check your home directory usage\ndu -sh ~/*\n\n# Find large files in home\nfind ~ -type f -size +100M -exec ls -lh {} \\;\n\n# Check scratch usage\ndu -sh /scratch/$USER\n\n# Find old files in scratch (not accessed in 30 days)\nfind /scratch/$USER -type f -atime +30 -exec ls -lh {} \\;\n\n# Clean conda cache to save space\nconda clean --all\n\n# Clean pip cache\npip cache purge\n</code></pre> <p>Keep track of system resources:</p> <pre><code># Check overall system resources\nbtop\n</code></pre>"},{"location":"mib/getting_started/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<p>We will add common issues and troubleshooting tips here as they arise. If you encounter any problems, feel free to reach out to David. If you fixed an issue yourself, consider documenting it in our Github Repo for future users. You can simply create a new issue with the details.</p>"},{"location":"mib/getting_started/#nccl-error","title":"NCCL Error","text":"<p>The most common error you will see with the Blackwell GPUs is the NCCL error, which may show up as a generic error in PyTorch or TensorFlow. This is because many packages (i.e. vLLM) ship with NCCL that are too old for the RTX PRO 6000 GPUs. To fix this, simply uninstall NCCL from your pip:</p> <pre><code>pip uninstall nvidia-nccl-cu12\n</code></pre> <p>The program should then use the system NCCL that is compatible.</p> <p>Success</p> <p>You're now ready to use the MIB server! Remember to be considerate of other users, communicate when you need significant resources, and clean up after your experiments. Happy computing!</p>"},{"location":"mib/transfer_files/","title":"Transfer Files","text":"<p>The MIB server has the following storage that are shared among users:</p> Storage Location Path Capacity Purpose Home Directory <code>/home/&lt;username&gt;</code> 50 GB per user Scripts, code, small files Scratch Storage <code>/scratch</code> 28 TB shared for all Datasets, checkpoints, outputs <p>The <code>/scratch</code> directory is also soft linked to your home directory for convenience. You can access it via <code>~/scratch</code>. If you want to transfer files to/from this folder, you will likely need to first transfer to/from your personal storage (pool at <code>/home/&lt;username&gt;/orcd/pool</code>, or scratch at <code>/home/&lt;username&gt;/orcd/scratch</code>), then move files while on the compute node.</p>"},{"location":"mib/transfer_files/#uploading-files-to-the-cluster","title":"Uploading Files to the Cluster","text":"<p>The easiest way to transfer files is using <code>rsync</code> over SSH. From your local machine, run: <pre><code># Basic syntax\nrsync -avz &lt;local_path&gt; &lt;mit_username&gt;@mib.media.mit.edu:&lt;remote_path&gt;\n\n# Upload a single file\nrsync -avz ~/Documents/data.csv dvdai@mib.media.mit.edu:~/\n\n# Upload an entire directory\nrsync -avz ~/Documents/project/ dvdai@mib.media.mit.edu:~/project/\n\n# Upload with progress bar\nrsync -avz --progress ~/largefile.zip dvdai@mib.media.mit.edu:~/\n</code></pre></p> <p>Useful <code>rsync</code> flags:</p> <ul> <li> <p><code>-a</code>: Archive mode (preserves permissions, timestamps)</p> </li> <li> <p><code>-v</code>: Verbose (shows files being transferred)</p> </li> <li> <p><code>-z</code>: Compression (faster for text files)</p> </li> <li> <p><code>--progress</code>: Shows transfer progress</p> </li> </ul>"},{"location":"mib/transfer_files/#downloading-files-from-the-cluster","title":"Downloading Files from the Cluster","text":"<p>From your local machine, use <code>rsync</code> to download files:</p> <pre><code># Download a file to current local directory\nrsync -avz dvdai@mib.media.mit.edu:~/results.csv ./\n\n# Download a directory\nrsync -avz dvdai@mib.media.mit.edu:/scratch/project/ ~/Downloads/project/\n</code></pre>"},{"location":"mib/transfer_files/#downloading-from-the-internet","title":"Downloading from the Internet","text":"<p>On the cluster, you can also download files directly from the internet using <code>wget</code> or <code>curl</code>: <pre><code># Direct download with wget\nwget https://example.com/dataset.zip\n\n# Download with custom filename\nwget -O mydata.zip https://example.com/dataset.zip\n\n# Download to specific directory\ncd /scratch/datasets\nwget https://example.com/largefile.tar.gz\n</code></pre></p> <p>For Google Drive files, you can use <code>gdown</code>: <pre><code>pip install gdown\ngdown https://drive.google.com/uc?id=FILE_ID\n</code></pre></p> <p>For Kaggle datasets, use the Kaggle CLI: <pre><code>pip install kaggle\nkaggle datasets download -d dataset-name\n</code></pre></p> <p>Back to the Getting Started Guide.</p>"}]}